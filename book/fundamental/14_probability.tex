\chapter{Basic probability}
% TODO missing probability concepts
% http://sahilmohnani.wordpress.com/2013/06/03/the-multinomial-and-poisson-distributions/
% - http://sahilmohnani.wordpress.com/2013/06/03/the-chi-square-distribution/
% - Stem-and-leaf plot example http://www.purplemath.com/modules/stemleaf.htm
% - Statistical vs non statistical questions (average vs deterministic)
% - probability models (should probabilities sum to 1)
% Normal distribution https://www.mathsisfun.com/data/standard-normal-distribution.html and https://statistics.laerd.com/statistical-guides/normal-distribution-calculations.php
% - area under the curve
% - http://www.countbayesie.com/blog/2015/3/17/interrogating-probability-distributions
% PDF http://en.wikipedia.org/wiki/Probability_density_function

% - http://jeremykun.com/2013/01/04/probability-theory-a-primer/
% - http://jeremykun.com/2013/03/28/conditional-partitioned-probability-a-primer/
% - http://jeremykun.com/2014/03/03/martingales-and-the-optional-stopping-theorem/
% “law of large numbers,” a major result in the theory of probability. The law of large numbers gives the precise mathematical result that corresponds to the well-known fact that the relative frequency of an event will more accurately predict the likelihood of its occurrence the more trials you observe.

# TODO missing problems to introduce
# - Birthday paradox The question is, How many randomly selected people do you need to assemble in a room for there to be a better-than-even chance that two of them will have the same birthday? The most common answer is 183, just over one-half the number of days in a year. The correct answer is 23. The exact calculation is a bit intricate, but you get a sense of why the answer is so low when you realize that with 23 people, there are 23 × 22 = 506 possible pairs, each of which might share a birthday, and this turns out to be just enough pairs to tilt the odds to 0.508 in favor of there being a match.
# - formal math for montey hall.

% Odds and expectation
% The law of large numbers
% counting rules
% binominal distribution
% normal disttibution
% monte carlo
% game theory

Odds are used by casinos, racetracks, and other gambling establishments to determine payoffs when bets are made. For example, at a race, the odds that a horse wins the race may be 4 to 1. In this case, if you bet $1$ and the horse wins, you get $4$. If you bet $2$ and the horse wins, you get $8$ and so on. suppose you roll a die and if you roll a 3, you win. what amount should you win if you bet 1 on average you win once in every six rolls. So if you lose on the first five rolls and win on the sixth, you have lost $5$; therefore, you should get $5$ if you win on the sixth roll, thus the odds 1 go 5 In gambling games, the odds are expressed in reverse order. For example, if there is one chance in six that you will win, the odds are 1 to 5, but in general, the odds would be given as 5 to 1. In gambling, the house (the people running the game) will offer lower odds, say 4 to 1, in order to make a profit. In this case, then, the player wins on average one time in every six rolls and spends on average $5$, but when the player wins, he gets only $4$. So the house wins on average $1$ for every six rolls of the player. If the odds of winning the game are 1:5, then the odds of losing are 5:1.

One die is rolled; what are the odds in favor of getting a 5 or 6? (1:2)

\begin{equation}\label{prob:odds}
P(event) = \frac{\text{Number of outcomes in favor event}}{\text{Number of outcomes not in favor of event}}
\end{equation}

% reducing sample space
Find the probability of getting a sum of 5 if it is known that the sum of the spots on the dice was odd. There are four ways to get a sum of 5. They are (1, 4), (2, 3), (3, 2), (4, 1), and there are 18 ways to get a sum that is odd; hence, P(sum of 5|sum is odd)= 4/18 alternativly we can use the formula P(sum of 5 and sum is odd) = P(sum of 5) * P(sum is ods|sum of 5) = 4/36 * 1 (as its certain the sun is odd if it was five) 4/36/(1/2) = 4/18

$4/36 * 18/36$

the addition rules. Here one is interested in finding the probability of one event or another event occurring. In these situations, you must consider whether or not both events have common outcomes.
% TODO use black or a 7 card example to show outcomes counted twice
what is the probability that the card is a king or a queen? = mutual exclusive as card cannot be both king and queem thus prob is 4/52 + 4/52 however what is the probability that the card is a king or a diamond = not mutual exclusive as card could be king of diamons = 13 + 4 - 1/52

If A and B are two events that are not mutually exclusive, then P(A or B) = P(A) + P(B) − P(A and B), where A and B means the number of outcomes event A and event B have in common. Adie is rolled. Find the probability of getting an odd number or a number less than 5. $3/6 + 4/6 - 2/6 = 5/6$
For the mathematical purist, only one addition rule is necessary, and that is   P(A or B) = P(A) + P(B) − P(A and B)   The reason is that when the events are mutually exclusive, P(A and B) is equal to zero because mutually exclusive events have no outcomes in common.

% TODO add to index: dependent, independent, mutually excluaive, classical and emperical probabikity, odds, expecgation
Two events, A and B, are said to be independent if the fact that event A occurred does not affect the probability that event B occurs. For example, if a coin is tossed and then a die is rolled, the outcome of the coin in no way affects the outcome, or changes the probability of the outcome, of the die. the first event in some way changes the probability of the occurrence of the second event, the two events are said to be dependent. For example, suppose a card is selected from a deck and not replaced, and a second card is selected. In this case, the probability of selecting any specific card on the first draw is , but since this card is not replaced, the probability of selecting any other specific card is since there are only 51 cards left.

only one multiplication rule is necessary for two events, and that is   P(A and B) = P(A) · P(B|A).   The reason is that when the events are independent, P(B|A) = P(B),

when two independent events occur in sequence, the probability that both events will occur can be found by multiplying the probabilities of each individual event.

% TODO solve using both sample space ans multiplicatiin rule (getting two heads and head on coind + 4 on die)

Probabilities can be computed for situations that do not use sample spaces. In these cases, frequency distributions are used and the probability is called empirical probability.
\begin{equation}\label{prob:frequency-event}
P(event) = \frac{\text{Frequency of event}}{\text{Sum of all frequencies}}
\end{equation}

Another aspect of empirical probability is that if a large number of subjects (called a sample) is selected from a particular group (called a population). we can never know the exact probability for the population onlyy for the sample, however if the sample is representative of the population, the estimate will usually be fairly close to the exact probability. Statisticians have a way of computing the accuracy (called the margin of error) for these situations.
% TODO aplit sectiins between classical and emperical probability
% - create example from mortality table
% - probability to live
% 50 or older
% Under 30 years old
% Between 40 and 59 years old
% Under 60 but over 29 years old




Probability theory is the basis on which statistics and with it a many of mathematics most useful applied subjects rest upon. The ability to calculate probabilities transformed statistics from mere data collection to using data to make informed decisions. Today politicians try to predict voter behavior through opionen polling. Marketing departments study customers to figure out how best to launch new products and in medicine statistics is used to compare the benefits drugs with their risks.

\myindent In spite of their obvious usefulness, probability and statistics are rather new branches of mathematics. Some of the earliest studies of probability comes from gambling. In the sixteenth century Gerolamo Cardano\index{Gerolamo Cardano} demonstrated the efficacy of defining odds as the ratio of favorable to unfavorable outcomes. Later these ideas was picked up and expanded upon by Pierre de Fermat\index{Pierre de Fermat} and Blaise Pascal\index{Blaise Pascal}. In recent years the study of probability and statistics has gained pace as computers allows us to perform studies on ever larger samples.

\myindent In 1494 Luca Pacioli\index{Luca Pacioli} first published the challenge that let Pascal and Fermat to undertake the formal study of probability. The challenge is known as the problem of the unfinished game. Suppose two players $\{A, B\}$ bets on who will win the best of five coin tosses, but then have to stop before either player has won. How do they divide the pot?. If each has won the same number of throws then the pot is split evenly. But what if they stop after three throws, with player $A$ ahead $2\text{-to-}1$?. Pacioli, suggested that the solution is to divide the pot according to the current state of play, namely $2\text{-to-}1$. But in $1539$ Cardano demonstrated that this is incorrect as splitting the pot depended not on how many rounds each player had already won but on how many each player must still win in order to win the contest. To see this consider that as $A$ is ahead $2\text{-to-}1$, the first three rounds must have yielded two heads and one tail. The remaining two throws can yield $\{H,H\}$, $\{H,T\}$, $\{T,H\}$, $\{T,T\}$. In the first scenario $\{H,H\}$, the final score is four heads and one tail, so player $A$ wins; in the second and the third ($\{H,T\}$ and $\{T,H\}$), the final outcome is three heads and two tails, so again player $A$ wins. Only in the fourth scenario with $\{T,T\}$ is the final outcome two heads and three tails, so player $B$ wins. This means that player $A$ wins in three of the four possible ways the game could have ended and thus the pot should be divided $3/4$ for $A$ and $1/4$ for for $B$.

\section{Classical probability}
\epigraph{"I can as easily throw one, three or five as two, four or six. The wagers there are laid in accordance with this equality if the die is honest."}{\textup{Gerolamo Cardano}, Liber de ludo aleae (Book of Games of Chance)}

In the quote above Cardano states that with a fair die the probability of getting $\{1,3,5\}$ is the same as getting $\{2,4,6\}$. He thus formulated one of the earliest known examples of the probability of an event as a fraction: the number of events that meets a constraint (such as a die being even or odd) divided by the total number of possible outcomes (such as the six different faces of a die).
\begin{equation}\label{prob:formula}
P(event) = \frac{\text{Number of events that meet constraint}}{\text{Number of equally likely events}}
\end{equation}
For example a toss of a fair coin has a set of two possible outcomes $\{H,T\}$ known as its \index{sample space}sample space with each possible outcome of the sample space having likelihood $1/2$ of occurring ($50$ percent chance of head or tails). So the probability of the event heads occurring is $P(H) = 1/2$. Similarly a toss of a die has a sample space consisting of $6$ equally likely possible outcomes $\{1, 2, 3, 4, 5, 6\}$ so the probability of the die showing six is $P(6) = 1/6$.

When constructing a sample space for a probability experiment such as drawing cards, throwing dice or flipping coins its important to assign probabilities to all possible outcomes and the sum of these should be exactly $1$. Further the probability of a event will always be a number from $0$ to $1$, where $0$ means that a event cannot occur (such as throwing $7$ with a die) and $1$ means that a event is certain to occur (such as getting a number less than $7$ with a die). The events described above are called simple events\index{Simple event} as they consists of one outcome. When an event consists of more than one outcome it's called a compound event. The probability of getting an odd number when a die is rolled is a compound event as there are three outcomes $1, 3$ and $5$ from the sample space that matches the event. On the other hand if two coins are tossed, the event of getting two heads is a simple event as there is only one way to get two heads with two coins.

\subsection{Product rule}

Cardano next observed that the probability of getting a certain outcome on two successive throws is the square of the probability of getting it on a single throw. For example, the probability of getting double $6$ is $1/6 \times 1/6 = 1/36$, this can be readily seen as the sample space consist of all the 36 enumerations of the possible ways two dice can be rolled and only one of these outcomes is double $6$ (see chapter \ref{combi} for a intro to combinatorics)

Similarly, the probability of getting three even numbers is $1/2 \times 1/2 \times 1/2 = 1/8$ (this assumes that is the events are \index{Independent event}independent events, i.e. that the first throw does not influence the second). That is the probability of two independent events $A$ and $B$ both occurring is
\begin{equation}\label{prob:compound-event}
P(A \text{ and } B) = P(A) \times P(B)
\end{equation}
With multiple independent events occurring the probability off all of them occuring is the product of the likelihood of each individual event. So, if the probability of you finishing this chapter is $9/10$, and the probability of you finishing the next one is also $9/10$, then the total probability of you finishing both chapters isn't $9/10$ but instead $9/10 \times 9/10 = 81/100$. Note if you remove the restriction on the order in which the events occurs then there are more possibilities. For example, the probability of rolling a $6$ followed by an even number is $1/6 \times 1/2 = 1/12$ but without the restriction of order it becomes $5/36$. The easiest way to see this is to count all the possible outcomes of throwing two dies $6 \times 6 = 36$ and then count the number of favorable outcomes (the die is even or six) $\{2,6\}$, $\{6,2\}$, $\{4,6\}$, $\{6,4\}$, and $\{6,6\}$. As there are five such outcomes we arrive at $5/36$.

\myindent Cardano next considered examples where we are interested in any of two \index{Mutually exclusive event} mutually exclusive events. That is two events that cannot occur at the same time, such as getting heads and tails on the same coin flip i.e $P(H \text{ and } T) = 0$. He observed that given
\begin{equation}\label{prob:exclusive-event}
P(A \text{ or } B) = P(A) + P(B)
\end{equation}
So the probability of getting one or six is $P(1 \text{ or } 6) = 1/6 + 1/6 = 1/3$ and probability of even number as $P(even) = P(2 \text{ or } 4 \text{ or } 6) = 3/6$ and the odds of getting a $1$ or an even number are $1/6 + 3/6 = 2/3$.

\myindent Finally Cardano’s also calculated the probability of throwing a $1$ or a $2$ with a pair of dice. The probability of throwing a $1$ or a $2$ with a single die is $1/3$, so the naive answer would be that with two dice the probability is $2/3$. Cardano observed this was incorrect as the probability of not rolling $1$ or $2$ with a single die is $4/6 = 2/3$, so the probability of not rolling it with two dice is $2/3 \times 2/3 = 4/9$. Hence the probability of rolling a $1$ or a $2$ must be $1 - 4/9 = 5/9$. This last scenario is a example of complementary event\index{Complementary events}. Complementary events are events that when add together to equal a whole.
\begin{equation}\label{prob:complementary-event}
P(A^c) = 1 - P(A)
\end{equation}
Here $P(A^c)$ means the complement of event $A$. For example, if the probability of it raining today were $2/5$, the probability of it not raining would be $1 - 2/5 = 3/5$.
% The probability that an event will not occur is equal to 1 minus the probability that the event will occur.

\subsection{Conditional probability}
From Cardano's early results and Fermat and Pascals' study of the unfinished game it was made clear that probabilities functioned very differently based on the nature of the events studied. In $1657$ the dutch mathematician Christiaan Huygens\index{Christiaan Huygens} published his \textit{De ratiociniis in ludo aleae} ("On Reasoning in Games of Chance") in which he studied dependent events\index{Dependent events} and conditional probability\index{Conditional probability}. Conditional probability is the probability of an event happening given that another event has occurred. Formally we write $P(B|A)$ meaning "the probability of event B given event A"
\begin{equation}\label{prob:conditional-event}
P(A \text{ and } B) = P(A) \times P(B|A)
\end{equation}
For example if we have $2$ blue and $3$ red marbles in a bag, then the chance of getting a blue marble is $2/5$. But after removing one marble the chances change. If we got a red marble then the chance of picking a blue now is $2/4$, but if we got a blue then the chance of getting another is $1/4$. Thus the probability of drawing two blue marbles is
\[
P(\text{first blue}) \times P(\text{second blue}|\text{first blue}) = 2/5 \times 1/4 = 1/10
\]
Note if we replace the marbles in the bag each time with new ones so there are always $2$ blue and $3$ red marbles, then the chances do not change and the events become independent

\myindent The most famous problem of conditional probabilities is likely the \index{Monty Hall problem}Monty Hall problem. At the last round of a game show, you’re faced with three curtains. Behind one there is a car but behind the two others there is a goat. You’re asked by the presenter to make a first choice. He then reveals one of the curtains you haven’t chosen which contains a goat. The presenter then offers you a chance to change your mind and switch curtain. Should you switch your choice or stick to the origiginal one. To most peoples surprise the correct answer is that you should switch your choice after being given this additional information. To see this consider the following table of posible actions
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{door 1} & \textbf{door 2} & \textbf{door 3} \\ \hline
stay            & switch          & switch          \\ \hline
switch          & stay            & switch          \\ \hline
switch          & switch          & stay            \\ \hline
\end{tabular}
\end{table}
that is if the car is behind door one and you chose door one you should stay, if you chose door two or three you should switch, equally for door two and three. From this table its easy to count that you should swich $6$ out of $9$ times which is therefor the best strategy.

If this kind of thinking seams counter intuitive consider the following statement “I have two children, and at least one of them is a girl.” What is the probability that I have a boy and a girl?. It will be tempting to say $50$ percent however if we list the complete sample space for my family $\{\text{Boy}-\text{Boy}, \text{Boy}-\text{Girl}, \text{Girl}-\text{Boy}, \text{Girl}-\text{Girl}\}$ we see that the information that I have at least one girl reduces it to $\{\text{Boy}-\text{Girl}, \text{Girl}-\text{Boy}, \text{Girl}-\text{Girl}\}$ meaning that the probability of me having a girl is $2/3$  having children of both sexes to be 2/3 and the probability of his having two girls as 1/3. Thus, he is (from your perspective) twice as likely to have a boy and a girl as he is to have two girls.

\section{Random variable}
\subsection{Expected return}
% TODO http://en.m.wikipedia.org/wiki/Expected_return
Expected gain is generally regarded as the correct objective measure (in most cases) of the value of a particular wager to the person who makes it. To compute it, you multiply the probability of each outcome by the amount that will be won (or lost, which you count as a negative gain) and add all the results together. For example, casinos offer even odds for betting on red or black at roulette. Suppose you bet $100$ on red. The roulette wheel has 36 slots, numbered from 1 to 36, half of them colored red, half black, and two zeros, colored green. The probability of red coming up is therefore 18/38, that is, 9/19. So your expectation (to the nearest cent) is: (9/19 × 100) + (10/19 × -100) = -100/19 = -5.26 This means that if you play repeatedly, betting 100 on red each time, then on average, you will lose 5.26 on each game. To put it another way, you can expect your losses to average 5.26 a game.

\section{Probability space}
A probability spaces is a way to models processes consisting of states that occur randomly. For example in a deck of 52 cards the sample space is a 52-element set, as each card is a possible outcome. Since there can be many outcomes (even infinitely many), outcomes elements are grouped into sets which are called "events. For our deck of cards, possible events may include
\begin{description}
\item [- The 5 of Hearts] (1 element),
\item [- A King] (4 elements),
\item [- A Face card] (12 elements),
\item [- A card] (52 elements).
\end{description}
More formally an event, is any subset of the sample space we like to consider in our model, including the empty set (an impossible event, with probability zero) and the sample space itself (a certain event, with probability one).

\noindent To sum up a probability space consists of three parts
\begin{itemize}
\item The sample space $\Omega$ which is a set of all possible outcomes.
\item The $\sigma$-algebra $\mathcal{F}$ which is a collection of the events we would like to consider.
\item The probability measure $P$ which is a function returning an event's probability $P: F \rightarrow [0,1]$.
\end{itemize}

For example if the experiment consists of just one flip of a perfect coin, then the outcomes are either heads or tails: $\Omega = {H, T}$. The $\sigma$-algebra $\mathcal{F} = 2^{\Omega}$ contains $2^2 = 4$ events, namely:
\begin{itemize}
\item $\{H\}$ – "heads"
\item $\{T\}$ – "tails",
\item $\{\}$ – "neither heads nor tails"
\item $\{H,T\}$ – "either heads or tails"
\end{itemize}
So, $\mathcal{F} = \{\{\}, \{H\}, \{T\}, \{H,T\}\}$. Since there is a fifty percent chance of tossing heads, and fifty percent for tails the probability measure in this example is $P(\{\}) = 0, P(\{H\}) = 0.5, P(\{T\}) = 0.5, P(\{H,T\}) = 1$.

\subsection{Random variable}
A random variable (or stochastic variable) is a variable whose value is subject to variations due to chance. A random variable's possible values might represent the possible outcomes of a yet-to-be-performed experiment

The mathematical function describing the possible values of a random variable and their associated probabilities is known as a probability distribution. Random variables can be discrete, that is, taking any of a specified finite list of values; or continuous, taking any numerical value in an interval.

\section{Propability distributions}
%\subsection{Poison distribution}
\subsection{Binomial distribution}
%\subsection{Negative binomial distribution}
%\subsection{Compound distributions}
\subsection{Normal distribution}
%\subsection{Gamma distribution}
%\subsection{Lognormal distribution}
%\subsection{Pareto distribution}
%\subsection{Chi-squared distribution}

\section{Bayes theorem}
Bayes’ theorem is a method for revising a probability in light of new information. It does not tell you how to assign a initial probability to an event instead its a iterative method that refines your starting probability when new information arrises. It was developed by Thomas Bayes ($1701-1761$) a presbyterian minister who dabbled with statistics in his spare time, however it was largely forgotten until the advent of computers. With modern computers Bayes theorem became a powerful tool for turning even quite poor initial probabilities into useful values.


You start out with a prior probability for the hypothesis $H$ when new information $E$ arises you carry out a calculation to obtain a revised probability, called the posterior probability, for $H$. This new value can then be used when new information arrises and in this manner we continously improve our estimate of the true probability of $H$.

Let $P(H)$ be the probability that the hypothesis $H$ is correct and $P(H|E)$ be the probability that $H$ is correct, given $E$. $P(E|H)$ be the probability that $E$ would be found if $H$ were correct, and finally let P(E|H_{wrong}) be the probability that $E$ would be found if $H$ were false.
\[
P(H|E) = \frac{P(H) \times P(E|H)}{P(H) \times P(E|H) + P(H_{wrong} \times P(E|H_{wrong})}
\]

The cancer has an incidence of 1 percent among the general population. Extensive trials have shown that the reliability of the test is 79 percent. More precisely, although the test does not fail to detect the cancer when it is present, it gives a positive result in 21 percent of the cases where no cancer is present—what is known as a false positive. When you are tested, the test produces a positive diagnosis. The question is, What is the probability that you have the cancer? If you are like most people, you will assume that if the test has a reliability rate of nearly 80 percent, and since you tested positive, the likelihood that you do indeed have the cancer is about 80 percent (i.e., the probability is approximately 0.8). Are you right? No. Given the scenario I just described, the likelihood that you have the cancer is just 4.6 percent (i.e., the probability is 0.046).

P(H) = 0.01 (the cancer has a 1 percent incidence in the population) P(E|H) = 1 (the test always shows positive if the cancer is present) P(Hwrong) = 0.99 (99 percent of the population is cancer-free ) P(E|Hwrong) = 0.21 (the test gives a false positive in 21 percent of cases)

To keep the arithmetic simple, I’ll assume a total population of exactly 10,000 people. Since all we are ultimately concerned about is percentages, this simplification will not affect the final answer. I’ll also assume that the various probabilities are reflected exactly in the actual numbers. Thus, of the total population of 10,000, precisely 100 will have the cancer and 9,900 will not. In the absence of the test, all you can say about the likelihood of your having the cancer is that there is a 1 percent chance that you do. This is the prior probability. Then you take the test, and it shows positive. How do you revise the probability that you have the cancer? Well, there are 100 individuals in the population who have the cancer, and for all of them, the test will correctly give a positive prediction, thereby identifying 100 individuals as having the cancer. Turning to the 9,900 cancer-free individuals, for 21 percent of them, the test will incorrectly give a positive result, thereby identifying 9,900 × 0.21 = 2,079 individuals, as having the cancer. Thus, in all, the test identifies a total of 100 + 2,079 = 2,179 individuals as having the cancer. Having tested positive, you are among that group. (This is precisely what the test evidence tells you.) The question is, Are you in the subgroup that really does have the cancer, or is your test result a false positive? Of the 2,179 identified by the test, 100 really do have the cancer. Thus, the probability of your being among that group is 100/2,179 = 0.0459.

\section{Exercises}

% TODO missing exercises
% - create excercise with tree people flipping coins and getting best out five but having to stop after two rounds (question of the three players who play in two throws. When the first has one [point] and the others none, your first solution is the true one and the division of the wager should be 17, 5, and 5. The reason for this is self-evident and it always takes the same principle, the combinations making it clear that the first has 17 chances while each of the others has but five.)
% - Exercise when throwing two dice is it better to bet on the total die showing 9 or 10
% -
% - excercise
% when throwing three dice its more prpbable that the total face value is 10 or 11 than 9 or 12 (why)

\begin{ExerciseList}

\Exercise This exercise will lead us to the solution of \index{de Méré's Problem}de Méré's Problem
\Question What is the probability of getting at least one "6" in one throw of two dice
\Question What is the probability of getting at least one "6" in two throws of a single die
\Question What is the probability of getting at least one "6" in four throws of a single die (51.77 percent.)
\Question What is the probability of getting at least one double "6" in 25 throws of two dice (50.55 percent)
\Answer
\begin{enumerate}
 \item\myindent $$.
 \item\myindent $$
 \item\myindent $$
 \item\myindent $$
\end{enumerate}
% http://math.stackexchange.com/questions/661692/find-the-probability-of-at-least-1-three-appearing-when-you-roll-4-dice-why-is
% http://math.stackexchange.com/questions/598838/if-i-roll-two-fair-dice-the-probability-that-i-would-get-at-least-one-6-would-b

\Exercise Two coins are tossed, find the probability:      
a.   Getting two heads. = 1/4
b.   Getting at least one tail. = 3/4  
c.   Getting two tails. = 1/4

\Exercise A coin is tossed and a die is rolled. Find the probability of getting     
 a.   A tail on the coin and a 5 on the die = 1/12
 b.   A tail on the coin  = 6/12    
 c.   A 3 on the die = 2/12
  
\Exercise When a card is selected at random from a deck, find the probability of getting      
a.   A club or a face card      
b.   A diamond or a 6      
c.   A black face card
\Answer    
a.   There are 13 clubs and 12 face cards, but the jack, queen, and king of clubs have been counted twice, so = 13 + 12 - 3/52 = 11/26     
b.   There are 13 diamonds and 4 sixes, but the 6 of diamonds has been counted twice, so = 13 + 4 - 1/52     
c.   There are 12 face cards, and half are black = 6/52

\Exercise what is the probability of rolling two dice and getting a sum of 6 or 10
\Answer the sample space contains 36 outcomes where 3 will be 10 (5;5 4;6 6;4) and 5 will be 6 1-5', 5-1, 2-4, 4-2, 3-3, (TODO check this))

\Exercise Two dice are rolled; find the probability of getting doubles or a sum of 6.
\Answer 6 double pairs and 5 ways of getting a sum 6 with one double pair being counted twice $6/36 + 5/36 - 1/36 = 5/18$

\Exercise using a ordinary deck of cards find the probability of
a. grrting two queens 4/52 * 3/51 = 1/221
b getting two cluba 13/52 * 12/51
c three cards dealt are hearths 13/52 * 12/51 * 11/50
d Find the probability that it is an ace given that it is a red card. = (2/52)/(1/2) = 26/2 (4/52 * 26/52 = 2/52 the probability of drawing a ace multiplied with chance of a red card) a red ace two red aces 1/2 = card is red)

     1.   When two dice are rolled, find the probability of getting doubles given that the sum of the spots is 10.      
     
     2.   Two coins are tossed. Find the probability of getting two heads if it is known that one of the coins is a head.      
     
     3.   A card is selected from a deck. Find the probability that it is a club given that it is a black card.
     
          5.   Three dice are rolled. Find the probability of getting exactly one 3 if it is known that the sum of the spots on the three dice was 5.
          
          Two dice are rolled; find the odds against getting a sum of 8. (31:5))
          
        1.   When a single card is drawn from a deck of 52 cards, find the odds against getting a queen. (48/4 = 12:1)    
         2.   When three coins are tossed, find the odds in favor of getting exactly two tails. (3/5 = 3:5)     
          3.   When two dice are rolled, find the odds in favor of getting a sum of 7.  (1-6,6-1,2-5,5-2,4-3,3-4) 6/30 = 1:5
           4.   When two dice are rolled, find the odds in favor of getting a sum of 11.  (5-6,6-5) 2/34= 1:17
            If the odds that an event will occur are 3:8, find the probability that the event will occur. 
                

\Exercise
Three coins are tossed. Find the probability of getting three heads if it is known that at least one head appeared on one of the coins. = 1/7

\Exercise If you role a fair six sided die and a fair four sided die what is the probability that neither will shown one
\Answer $P(\text{six sided not not one}) \cdot P(\text{four sided not not one}) = 5/6 * 3/4 = 5/8$

\Exercise You are given two dice to roll. One is black with six sides; the other is white with four sides. For a given roll, what is the probability the black die is even and the white die is $2$
\Answer $P(\text{even black die}) \cdot P(\text{white die is 2}) = 3/6 * 1/4 = 3/24$

\Exercise You are going to randomly select a marble from a bag of marbles that contains $3$ blue marbles, $4$ green marbles, and $5$ red marbles. What is $P(\text{blue marble})$
\Answer $P(blue marble) = \frac{\text{number of blue marbles}}{\text{total number of marbles}} = 3/12 = 0.25$

\Exercise A store offers sells four types of cloth: shirts, pants, socks and hats and offers each in three colors orange", purple and blue. If you randomly pick the piece of clothing and the color, what is the probability that you'll end up with an orange hat
\Answer $1/3 \cdot 1/4 = 1/12$

\Exercise If you flip a fair coin $1200$ times. What is the best prediction for the number of times that the coin will land heads up?
\Answer $1/2 \cdot 1200 = 600$

\Exercise If you toss a fair die $180$ times what is the best prediction of the number of times you will get more than $4$
\Answer $2/6 \cdot 180 = 60$

\Exercise You've decided to flip $3$ coins, how many possible outcomes are there.
\Answer There are two possible outcomes for the first flip, two for the second and two for the thrid, thus $2 \cdot 2 \cdot 2 = 8$ possible outcomes.

\Exercise If a pirate and a navy boat fires at each other simultaneously and the navy boat has $3/5$ probability of a hit and the pirate $1/3$. What is then the probability that the navy hits and the pirate misses ?
\Answer Our scenario has probability $P(\text{navy hits}) * P(\text{pirate misses})$ which is $3/5 \cdot (1 - 1/3) = 3/5 \cdot 2/3 = 6/15 = 2/5$.

\Exercise In a class of $7$, there are $3$ students who have red hair. If the teacher randomly chooses $2$ students, what is the probability that neither of them have red hair.
\Answer there is a $4/7$ chance that the first student is not a red hair and $3/6$ chance that the second student is not so $4/7 * 3/6 = 12/42 = (2*2*3)/(2*3*7) = 2/7$.

\Exercise Three dice are thrown simultaneously. Find the probability that:
\Question All show distinct faces
\Question Two of them show the same face
\Answer TODO % http://math.stackexchange.com/a/470067

\end{ExerciseList}
